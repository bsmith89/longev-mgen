{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data\n",
    "\n",
    "con = sqlite3.connect('res/core.1.denorm.db')\n",
    "\n",
    "# Relative Abundance\n",
    "rrs_count = (pd.read_sql('SELECT * FROM rrs_taxon_count;',\n",
    "                         con=con, index_col=['extraction_id', 'sequence_id'])\n",
    "               .tally.unstack().fillna(0).astype(int))\n",
    "rabund = rrs_count.apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "# Coverage\n",
    "bin_cvrg = (pd.read_sql(\"\"\"\n",
    "SELECT bin_id, extraction_id, SUM(coverage) AS coverage\n",
    "FROM bin_coverage\n",
    "JOIN library USING (library_id)\n",
    "GROUP BY bin_id, extraction_id;\"\"\",\n",
    "                        con=con, index_col=['extraction_id', 'bin_id'])\n",
    "              .coverage.unstack().fillna(0).apply(lambda x: x / x.sum(), axis=1))\n",
    "\n",
    "# Only keep shared extractions\n",
    "extractions = set(rabund.index) & set(bin_cvrg.index)\n",
    "rabund = rabund.loc[extractions]\n",
    "bin_cvrg = bin_cvrg.loc[extractions]\n",
    "\n",
    "# Taxonomy\n",
    "taxonomy = pd.read_sql('SELECT sequence_id, otu_id FROM rrs_taxon_count GROUP BY sequence_id;',\n",
    "                       con=con, index_col='sequence_id')\n",
    "name_map = {}\n",
    "for otu, d in (pd.DataFrame({'mean_rabund': rabund.mean(),\n",
    "                             'otu_id': taxonomy.otu_id})\n",
    "                 .sort_values('mean_rabund',\n",
    "                              ascending=False)\n",
    "                 .groupby('otu_id')):\n",
    "    for i, sequence_id in enumerate(d.index, start=1):\n",
    "        name_map[sequence_id] = '{}_{}'.format(otu, i)\n",
    "taxonomy['name'] = pd.Series(name_map)\n",
    "taxonomy['mean_rabund'] = rabund.mean()\n",
    "\n",
    "contig_bin = pd.read_sql(\"SELECT * FROM contig_bin\", con=con, index_col='contig_id')\n",
    "\n",
    "\n",
    "# Select abundant taxa and bins\n",
    "# TODO: Set these threshold as parameters\n",
    "major_taxa = taxonomy.index[taxonomy.mean_rabund > 0.0001]\n",
    "major_bins = bin_cvrg.columns[bin_cvrg.mean() > 0.0001]\n",
    "d_rabund = rabund[major_taxa].copy()\n",
    "d_rabund['other'] = rabund.drop(columns=major_taxa).sum(1)\n",
    "d_rabund.rename(columns=taxonomy.name, inplace=True)\n",
    "d_cvrg = bin_cvrg[major_bins].copy()\n",
    "d_cvrg['other'] = bin_cvrg.drop(columns=major_bins).sum(1)\n",
    "\n",
    "d_rabund.shape, d_cvrg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_fit = PLSCanonical(scale=False, n_components=40).fit(d_cvrg.apply(np.sqrt), d_rabund.apply(np.sqrt))\n",
    "bin_otu_contrib = pd.DataFrame((pls_fit.x_loadings_ @ pls_fit.y_loadings_.T),\n",
    "                       index=d_cvrg.columns, columns=d_rabund.columns).rename(columns=taxonomy.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metabinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_mean_abund = 0.008\n",
    "tax_filter = lambda x: x.quantile(0.90) > 0.02\n",
    "\n",
    "taxa_of_interest = sorted(d_rabund.loc[:, tax_filter].rename(columns=taxonomy.name).columns)\n",
    "if 'other' in taxa_of_interest:\n",
    "    del taxa_of_interest[taxa_of_interest.index('other')]\n",
    "print(len(taxa_of_interest))\n",
    "\n",
    "\n",
    "\n",
    "factor = 1/3\n",
    "\n",
    "_hits = {}\n",
    "for tax in taxa_of_interest:\n",
    "    top_score = bin_otu_contrib[tax].max()\n",
    "    print(tax, top_score)\n",
    "    _hits[tax] = list((bin_otu_contrib[tax].sort_values(ascending=False) > top_score * factor)[lambda x: x].index)\n",
    "    \n",
    "print()\n",
    "for tax in _hits:\n",
    "    print(tax, _hits[tax])\n",
    "\n",
    "all_hits = set(chain(*_hits.values()))\n",
    "\n",
    "a = sns.clustermap(bin_otu_contrib.loc[all_hits, taxa_of_interest].rename(columns=taxonomy.name), robust=True,\n",
    "                   figsize=(14, 18), col_cluster=False, cmap='coolwarm', center=0)\n",
    "\n",
    "ax = a.fig.get_axes()[2]\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTU-3 Strain Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0003_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "                                  \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_1062998', 'core-k161_1089326',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.999].index\n",
    "\n",
    "valid_extractions = cvrg[trusted_contigs].mean(1)[lambda x: x > 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "#cvrg_norm = cvrg_norm.loc[valid_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "bgm = BayesianGaussianMixture(15,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_mean_mean_coverage * group_cvrg.group_std_mean_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['group_std_mean_coverage', 'length'], ascending=[True, False], inplace=True)\n",
    "order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "color_map = {'acarbose': 'goldenrod', 'control': 'darkblue',\n",
    "             'UM': 'darkblue', 'UT': 'darkgreen',\n",
    "             'male': 'blue', 'female': 'magenta',\n",
    "             'C2013': 'blue', 'Glenn': 'red'}\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[order].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "#ax.plot(cvrg_norm[order].loc['EXT-0086'].values, lw=2, color='k')\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > 1:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   I believe that group 5 is a large, missassembled contig.\n",
    "-   I believe that one or more of the over-abundant contigs in group 2 are plasmids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < 1].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > 1].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTU-1 Strain Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0001_1', 'Otu0001_2', 'Otu0001_3']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "                                  \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_586098', 'core-k161_186338',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "bgm = BayesianGaussianMixture(40,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_mean_mean_coverage * group_cvrg.group_std_mean_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['group_std_mean_coverage', 'length'], ascending=[True, False], inplace=True)\n",
    "order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "color_map = {'acarbose': 'goldenrod', 'control': 'darkblue',\n",
    "             'UM': 'darkblue', 'UT': 'darkgreen',\n",
    "             'male': 'blue', 'female': 'magenta',\n",
    "             'C2013': 'blue', 'Glenn': 'red'}\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[order].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "#ax.plot(cvrg_norm[order].loc['EXT-0086'].values, lw=2, color='k')\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > 1:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby(extraction_meta.site).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < 1].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < 1].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > 1].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTU-4 Strain Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0007_1', 'Otu0007_2']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "                                  \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 'core-k161_32879'  # Contig containing the 16S gene\n",
    "compare = 'core-k161_646850'  # Some other contig that we're confident is in this genome.\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg)\n",
    "\n",
    "# Contigs that are VERY closely linked with the 16S contig abundance (used for calibration)\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "\n",
    "# Extractions that have enough coverage of the trusted contigs to be worth examining.\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "bgm = BayesianGaussianMixture(30,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_mean_mean_coverage * group_cvrg.group_std_mean_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['group_std_mean_coverage', 'length'], ascending=[True, False], inplace=True)\n",
    "order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "color_map = {'acarbose': 'goldenrod', 'control': 'darkblue',\n",
    "             'UM': 'darkblue', 'UT': 'darkgreen',\n",
    "             'male': 'blue', 'female': 'magenta',\n",
    "             'C2013': 'blue', 'Glenn': 'red'}\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[order].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "#ax.plot(cvrg_norm[order].loc['EXT-0086'].values, lw=2, color='k')\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > 1:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby(extraction_meta.site).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < 1].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < 1].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > 1].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTU-2 Strain Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/2\n",
    "otus = ['Otu0002_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "bins = bins - set(['other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "                                  \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_368834', 'core-k161_2211409',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg)\n",
    "\n",
    "# Contigs that are VERY closely linked with the 16S contig abundance (used for calibration)\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "\n",
    "# Extractions that have enough coverage of the trusted contigs to be worth examining.\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "bgm = BayesianGaussianMixture(10,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_mean_mean_coverage * group_cvrg.group_std_mean_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['group_std_mean_coverage', 'length'], ascending=[True, False], inplace=True)\n",
    "order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "color_map = {'acarbose': 'goldenrod', 'control': 'darkblue',\n",
    "             'UM': 'darkblue', 'UT': 'darkgreen',\n",
    "             'male': 'blue', 'female': 'magenta',\n",
    "             'C2013': 'blue', 'Glenn': 'red'}\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[order].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "#ax.plot(cvrg_norm[order].loc['EXT-0086'].values, lw=2, color='k')\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > 1:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < 1].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > 1].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTU-5 Strain Variation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0005_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "bins = bins - set(['other'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "                                  \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_meta.length.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_395950', 'core-k161_572566',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg)\n",
    "\n",
    "# Contigs that are VERY closely linked with the 16S contig abundance (used for calibration)\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "\n",
    "# Extractions that have enough coverage of the trusted contigs to be worth examining.\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "\n",
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "bgm = BayesianGaussianMixture(10,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_mean_mean_coverage * group_cvrg.group_std_mean_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['group_std_mean_coverage', 'length'], ascending=[True, False], inplace=True)\n",
    "order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "color_map = {'acarbose': 'goldenrod', 'control': 'darkblue',\n",
    "             'UM': 'darkblue', 'UT': 'darkgreen',\n",
    "             'male': 'blue', 'female': 'magenta',\n",
    "             'C2013': 'blue', 'Glenn': 'red'}\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[order].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "#ax.plot(cvrg_norm[order].loc['EXT-0086'].values, lw=2, color='k')\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > 2:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < 2].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > 2].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "102px",
    "width": "189px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "205px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}