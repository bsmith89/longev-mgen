{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {'acarbose': 'goldenrod', 'control': 'darkblue',\n",
    "             'UM': 'darkblue', 'UT': 'darkgreen',\n",
    "             'male': 'blue', 'female': 'magenta',\n",
    "             'C2013': 'blue', 'Glenn': 'red'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data\n",
    "\n",
    "con = sqlite3.connect('res/core.1.denorm.db')\n",
    "\n",
    "# Relative Abundance\n",
    "rrs_count = (pd.read_sql('SELECT * FROM rrs_taxon_count;',\n",
    "                         con=con, index_col=['extraction_id', 'sequence_id'])\n",
    "               .tally.unstack().fillna(0).astype(int))\n",
    "rabund = rrs_count.apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "# Coverage\n",
    "bin_cvrg = (pd.read_sql(\"\"\"\n",
    "SELECT bin_id, extraction_id, SUM(coverage) AS coverage\n",
    "FROM bin_coverage\n",
    "JOIN library USING (library_id)\n",
    "GROUP BY bin_id, extraction_id;\"\"\",\n",
    "                        con=con, index_col=['extraction_id', 'bin_id'])\n",
    "              .coverage.unstack().fillna(0).apply(lambda x: x / x.sum(), axis=1))\n",
    "\n",
    "# Only keep shared extractions\n",
    "extractions = set(rabund.index) & set(bin_cvrg.index)\n",
    "rabund = rabund.loc[extractions]\n",
    "bin_cvrg = bin_cvrg.loc[extractions]\n",
    "\n",
    "# Phylotypes\n",
    "phylotype = pd.read_sql('SELECT sequence_id, otu_id FROM rrs_taxon_count GROUP BY sequence_id;',\n",
    "                       con=con, index_col='sequence_id')\n",
    "name_map = {}\n",
    "for otu, d in (pd.DataFrame({'mean_rabund': rabund.mean(),\n",
    "                             'otu_id': phylotype.otu_id})\n",
    "                 .sort_values('mean_rabund',\n",
    "                              ascending=False)\n",
    "                 .groupby('otu_id')):\n",
    "    for i, sequence_id in enumerate(d.index, start=1):\n",
    "        name_map[sequence_id] = '{}_{}'.format(otu, i)\n",
    "phylotype['name'] = pd.Series(name_map)\n",
    "phylotype['mean_rabund'] = rabund.mean()\n",
    "\n",
    "contig_bin = pd.read_sql(\"SELECT * FROM contig_bin\", con=con, index_col='contig_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTU Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = pd.read_sql('SELECT sequence_id, phylum_, class_, order_, family_, genus_ FROM taxonomy;',\n",
    "                       con=con, index_col='sequence_id').rename(phylotype.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select abundant taxa and bins\n",
    "# TODO: Set these threshold as parameters\n",
    "major_taxa = phylotype.index[phylotype.mean_rabund > 0.0001]\n",
    "major_bins = bin_cvrg.columns[bin_cvrg.mean() > 0.0001]\n",
    "d_rabund = rabund[major_taxa].copy()\n",
    "d_rabund['other'] = rabund.drop(columns=major_taxa).sum(1)\n",
    "d_rabund.rename(columns=phylotype.name, inplace=True)\n",
    "d_cvrg = bin_cvrg[major_bins].copy()\n",
    "d_cvrg['other'] = bin_cvrg.drop(columns=major_bins).sum(1)\n",
    "\n",
    "d_rabund.shape, d_cvrg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_rabund.mean().to_frame(name='mean_rabund').join(taxonomy).sort_values('mean_rabund', ascending=False).loc[['Otu0058_1', 'Otu0041_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_rabund.mean().to_frame(name='mean_rabund').join(taxonomy).sort_values('mean_rabund', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metabinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_fit = PLSCanonical(scale=False, n_components=40).fit(d_cvrg.apply(np.sqrt), d_rabund.apply(np.sqrt))\n",
    "bin_otu_contrib = pd.DataFrame((pls_fit.x_loadings_ @ pls_fit.y_loadings_.T),\n",
    "                       index=d_cvrg.columns, columns=d_rabund.columns).rename(columns=phylotype.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_filter = lambda x: x.quantile(0.95) > 0.01\n",
    "\n",
    "taxa_of_interest = sorted(d_rabund.loc[:, tax_filter].rename(columns=phylotype.name).columns)\n",
    "if 'other' in taxa_of_interest:\n",
    "    del taxa_of_interest[taxa_of_interest.index('other')]\n",
    "print(len(taxa_of_interest))\n",
    "\n",
    "\n",
    "\n",
    "factor = 1/3\n",
    "\n",
    "_hits = {}\n",
    "for tax in taxa_of_interest:\n",
    "    top_score = bin_otu_contrib[tax].max()\n",
    "    print(tax, top_score)\n",
    "    _hits[tax] = list((bin_otu_contrib[tax].sort_values(ascending=False) > top_score * factor)[lambda x: x].index)\n",
    "    \n",
    "print()\n",
    "for tax in _hits:\n",
    "    print(tax, _hits[tax])\n",
    "\n",
    "all_hits = set(chain(*_hits.values()))\n",
    "\n",
    "a = sns.clustermap(bin_otu_contrib.loc[all_hits, taxa_of_interest].rename(columns=phylotype.name), robust=True,\n",
    "                   figsize=(14, 18), col_cluster=False, cmap='coolwarm', center=0)\n",
    "\n",
    "ax = a.fig.get_axes()[2]\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Low-diversity OTUs (sanity check)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0003_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_1062998', 'core-k161_1089326',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(5,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage * np.log(group_cvrg.total_length)\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 100\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/core.a.mags.d/OTU-3.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([0, 2, 3, 1, 4])].index:\n",
    "        print(contig_id, file=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0002_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_578034', 'core-k161_2211409',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(10,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 2\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/core.a.mags.d/OTU-2.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([0])].index:\n",
    "        print(contig_id, file=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lachnospiraceae"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0015_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_meta.sort_values('length').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_1048491', 'core-k161_571666', \n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e4, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(10,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                              n_init=2,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 2\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/core.a.mags.d/OTU-15.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([5, 3, 0, 4])].index:\n",
    "        print(contig_id, file=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0025_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_meta[lambda x: x.bin_id=='bin00826'].sort_values('length').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_461086', 'core-k161_449184', \n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e4, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(30,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 2\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/core.a.mags.d/OTU-25.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([0, 6, 26, 15, 16, 28, 12])].index:\n",
    "        print(contig_id, file=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0032_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_1443667', 'core-k161_886844', \n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e4, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.999].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40, 5)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(30,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                              n_init=2,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 3\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/core.a.mags.d/OTU-32.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([16, 0, 17, 12, 3, 25, 6])].index:\n",
    "        print(contig_id, file=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other OTUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-12 (Ruminiclostridium)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0012_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)\n",
    "\n",
    "taxonomy.loc[otus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_meta[lambda x: x.bin_id.isin(['bin00559'])].sort_values('length').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_422699', 'core-k161_1821146',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(20,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 2.5\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "group_cvrg.sort_values('contamination_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/core.a.mags.d/OTU-12.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([0, 18, 6, 3, 7, 16, 17])].index:\n",
    "        print(contig_id, file=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-6 (Turicibacter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0006_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_meta[lambda x: x.bin_id=='bin01024'].sort_values('length').tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_2698281', 'core-k161_948080'\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e4, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(30,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 2\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "group_cvrg.sort_values('contamination_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/core.a.mags.d/OTU-6.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([3])].index:\n",
    "        print(contig_id, file=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-20 (Intestinimonas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0020_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)\n",
    "\n",
    "taxonomy.loc[otus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_288653', 'core-k161_535156',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(20,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage * np.log(group_cvrg.total_length)\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 30\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cvrg.sort_values('contamination_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import SymLogNorm\n",
    "\n",
    "colors = [(1, 1, 1), (0, 0.5, 0), (0, 0.8, 0)]  # R -> G -> B\n",
    "n_bins = [3, 6, 10, 100]  # Discretizes the interpolation into bins\n",
    "cmap_name = 'custom1'\n",
    "cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=100)\n",
    "\n",
    "d = (cvrg_norm.groupby(group_assign.group, axis='columns').median()\n",
    "              .loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index])\n",
    "\n",
    "vmin, vmax, cmap, norm = 0, 8, cm, SymLogNorm(linthresh=1, linscale=0.9)\n",
    "\n",
    "sns.clustermap(d[extraction_meta.site == 'UM'], vmin=vmin, vmax=vmax,\n",
    "               col_cluster=False, robust=True, cmap=cmap, norm=norm)\n",
    "sns.clustermap(d[extraction_meta.site == 'UT'], vmin=vmin, vmax=vmax,\n",
    "               col_cluster=False, robust=True, cmap=cmap, norm=norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with open('res/core.a.mags.d/OTU-20-UM.contigs.list', 'w') as handle:\n",
    "#    for contig_id in group_assign[lambda x: x.group.isin([0, 7, 17, 15, 6])].index:\n",
    "#        print(contig_id, file=handle)\n",
    "#        \n",
    "#with open('res/core.a.mags.d/OTU-20-UT.contigs.list', 'w') as handle:\n",
    "#    for contig_id in group_assign[lambda x: x.group.isin([0, 7, 11, 15, 6])].index:\n",
    "#        print(contig_id, file=handle)\n",
    "\n",
    "with open('res/core.a.mags.d/OTU-20.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([0, 6, 7, 8, 11, 15, 17])].index:\n",
    "        print(contig_id, file=handle)\n",
    "        \n",
    "# Groups 11 and 17 seem to differentiate the two sites pretty well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-35\t(Ruminococcaceae_UCG-014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0035_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)\n",
    "\n",
    "taxonomy.loc[otus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_meta[lambda x: x.bin_id=='bin00425'].sort_values('length').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_382136', 'core-k161_2295479',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(10,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 2\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "group_cvrg.sort_values('contamination_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/core.a.mags.d/OTU-35.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([1])].index:\n",
    "        print(contig_id, file=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-58 (Mollicutes sp.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0058_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_367789', 'core-k161_1175581',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(20,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 2\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < 1].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > 1].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < 1].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/core.a.mags.d/OTU-58.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([12, 11, 7])].index:\n",
    "        print(contig_id, file=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-41 (Bacteroides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0041_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)\n",
    "\n",
    "taxonomy.loc[otus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_meta[lambda x: x.bin_id=='bin01631'].sort_values('length').tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_514932', 'core-k161_2549350',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "#_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(20,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 2\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "group_cvrg.sort_values('contamination_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('res/core.a.mags.d/OTU-41.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([7, 17])].index:\n",
    "        print(contig_id, file=handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do any MAGs share contigs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "alldata = []\n",
    "for filepath in glob('res/core.a.mags.d/*.contigs.list'):\n",
    "    otu = filepath.split('/')[-1].split('.')[0]\n",
    "    df = pd.read_table(filepath, names=['contig_id'])\n",
    "    df['otu_id'] = otu\n",
    "    alldata.append(df)\n",
    "all_contigs = pd.concat(alldata)\n",
    "all_contigs['present'] = 1\n",
    "all_contigs = all_contigs.set_index(['contig_id', 'otu_id'])\n",
    "\n",
    "all_contigs.unstack(fill_value=0)[lambda x: x.sum(1) > 1].sum()\n",
    "# Only OTU-1-UM and OTU-1-UT share any contigs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(all_contigs.present.unstack(fill_value=0)\n",
    "            [lambda x: x.sum(1) > 1][lambda x: x['OTU-49'] > 0]\n",
    "            [['OTU-1-UM', 'OTU-1-UT', 'OTU-49']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_bin.loc[['core-k161_1003382', 'core-k161_90922']]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "102px",
    "width": "189px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "216px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}