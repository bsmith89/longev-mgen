{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import chain\n",
    "\n",
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sklearn.cross_decomposition import PLSCanonical\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "from matplotlib import animation\n",
    "from IPython.display import HTML\n",
    "\n",
    "## Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "color_map = {'acarbose': 'goldenrod', 'control': 'darkblue',\n",
    "             'UM': 'darkblue', 'UT': 'darkgreen',\n",
    "             'male': 'blue', 'female': 'magenta',\n",
    "             'C2013': 'blue', 'Glenn': 'red'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the data\n",
    "\n",
    "con = sqlite3.connect('res/core.1.denorm.db')\n",
    "\n",
    "# Relative Abundance\n",
    "rrs_count = (pd.read_sql('SELECT * FROM rrs_taxon_count;',\n",
    "                         con=con, index_col=['extraction_id', 'sequence_id'])\n",
    "               .tally.unstack().fillna(0).astype(int))\n",
    "rabund = rrs_count.apply(lambda x: x / x.sum(), axis=1)\n",
    "\n",
    "# Coverage\n",
    "bin_cvrg = (pd.read_sql(\"\"\"\n",
    "SELECT bin_id, extraction_id, SUM(coverage) AS coverage\n",
    "FROM bin_coverage\n",
    "JOIN library USING (library_id)\n",
    "GROUP BY bin_id, extraction_id;\"\"\",\n",
    "                        con=con, index_col=['extraction_id', 'bin_id'])\n",
    "              .coverage.unstack().fillna(0).apply(lambda x: x / x.sum(), axis=1))\n",
    "\n",
    "# Only keep shared extractions\n",
    "extractions = set(rabund.index) & set(bin_cvrg.index)\n",
    "rabund = rabund.loc[extractions]\n",
    "bin_cvrg = bin_cvrg.loc[extractions]\n",
    "\n",
    "# Phylotypes\n",
    "phylotype = pd.read_sql('SELECT sequence_id, otu_id FROM rrs_taxon_count GROUP BY sequence_id;',\n",
    "                       con=con, index_col='sequence_id')\n",
    "name_map = {}\n",
    "for otu, d in (pd.DataFrame({'mean_rabund': rabund.mean(),\n",
    "                             'otu_id': phylotype.otu_id})\n",
    "                 .sort_values('mean_rabund',\n",
    "                              ascending=False)\n",
    "                 .groupby('otu_id')):\n",
    "    for i, sequence_id in enumerate(d.index, start=1):\n",
    "        name_map[sequence_id] = '{}_{}'.format(otu, i)\n",
    "phylotype['name'] = pd.Series(name_map)\n",
    "phylotype['mean_rabund'] = rabund.mean()\n",
    "\n",
    "contig_bin = pd.read_sql(\"SELECT * FROM contig_bin\", con=con, index_col='contig_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = pd.read_table('meta/library.tsv', index_col='library_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OTU Details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxonomy = pd.read_sql('SELECT sequence_id, phylum_, class_, order_, family_, genus_ FROM taxonomy;',\n",
    "                       con=con, index_col='sequence_id').rename(phylotype.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select abundant taxa and bins\n",
    "# TODO: Set these threshold as parameters\n",
    "major_taxa = phylotype.index[phylotype.mean_rabund > 0.0001]\n",
    "major_bins = bin_cvrg.columns[bin_cvrg.mean() > 0.0001]\n",
    "d_rabund = rabund[major_taxa].copy()\n",
    "d_rabund['other'] = rabund.drop(columns=major_taxa).sum(1)\n",
    "d_rabund.rename(columns=phylotype.name, inplace=True)\n",
    "d_cvrg = bin_cvrg[major_bins].copy()\n",
    "d_cvrg['other'] = bin_cvrg.drop(columns=major_bins).sum(1)\n",
    "\n",
    "d_rabund.shape, d_cvrg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_rabund.mean().to_frame(name='mean_rabund').join(taxonomy).sort_values('mean_rabund', ascending=False).loc[['Otu0058_1', 'Otu0041_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_rabund.mean().to_frame(name='mean_rabund').join(taxonomy).sort_values('mean_rabund', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metabinning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pls_fit = PLSCanonical(scale=False, n_components=40).fit(d_cvrg.apply(np.sqrt), d_rabund.apply(np.sqrt))\n",
    "bin_otu_contrib = pd.DataFrame((pls_fit.x_loadings_ @ pls_fit.y_loadings_.T),\n",
    "                       index=d_cvrg.columns, columns=d_rabund.columns).rename(columns=phylotype.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tax_filter = lambda x: x.quantile(0.95) > 0.01\n",
    "\n",
    "taxa_of_interest = sorted(d_rabund.loc[:, tax_filter].rename(columns=phylotype.name).columns)\n",
    "if 'other' in taxa_of_interest:\n",
    "    del taxa_of_interest[taxa_of_interest.index('other')]\n",
    "print(len(taxa_of_interest))\n",
    "\n",
    "\n",
    "\n",
    "factor = 1/3\n",
    "\n",
    "_hits = {}\n",
    "for tax in taxa_of_interest:\n",
    "    top_score = bin_otu_contrib[tax].max()\n",
    "    print(tax, top_score)\n",
    "    _hits[tax] = list((bin_otu_contrib[tax].sort_values(ascending=False) > top_score * factor)[lambda x: x].index)\n",
    "    \n",
    "print()\n",
    "for tax in _hits:\n",
    "    print(tax, _hits[tax])\n",
    "\n",
    "all_hits = set(chain(*_hits.values()))\n",
    "\n",
    "a = sns.clustermap(bin_otu_contrib.loc[all_hits, taxa_of_interest].rename(columns=phylotype.name), robust=True,\n",
    "                   figsize=(14, 18), col_cluster=False, cmap='coolwarm', center=0)\n",
    "\n",
    "ax = a.fig.get_axes()[2]\n",
    "ax.set_yticklabels(ax.get_yticklabels(), rotation=0)\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation=90)\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Metabinning (raw correlation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu1_metabinning_results = {'bin00070', 'bin01973', 'bin01832', 'bin01258', 'bin01621', 'bin01464', 'bin00183', 'bin01169', 'bin01527', 'bin01379', 'bin00503', 'bin01784', 'bin01256', 'bin01978', 'bin00069', 'bin01824', 'bin00512', 'bin01804', 'bin01408', 'bin01311', 'bin01449', 'bin00399', 'bin01178', 'bin00491', 'bin00730', 'bin00597'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu_rabund = d_rabund.groupby(d_rabund.columns.map(lambda s: s.split('_')[0]), axis='columns').sum()\n",
    "bin_corrs = d_cvrg.apply(lambda x: sp.stats.pearsonr(otu_rabund['Otu0001'], x)[0]).sort_values(ascending=False)\n",
    "bin_corrs[['bin00183', 'bin00069']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metabin Refinement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0001_1', 'Otu0001_2', 'Otu0001_3', 'Otu0001_4']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "#cvrg = cvrg.div(extraction_meta.coverage, axis=0).loc[d_rabund.index]\n",
    "cvrg = cvrg.loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_586098', 'core-k161_186338',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(40,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage * np.log(group_cvrg.total_length)\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 40\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: ( x.contamination_score > contam_threshold)\n",
    "                                                                | x.contamination_score.isna()\n",
    "                                                     ].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "from matplotlib.colors import SymLogNorm\n",
    "\n",
    "colors = [(1, 1, 1), (0, 0.5, 0), (0, 0.8, 0)]  # R -> G -> B\n",
    "n_bins = [3, 6, 10, 100]  # Discretizes the interpolation into bins\n",
    "cmap_name = 'custom1'\n",
    "cm = LinearSegmentedColormap.from_list(cmap_name, colors, N=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (cvrg_norm.groupby(group_assign.group, axis='columns').median()\n",
    "              .loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index])\n",
    "\n",
    "vmin, vmax, cmap, norm = 0, 8, cm, SymLogNorm(linthresh=1, linscale=0.9)\n",
    "\n",
    "sns.clustermap(d[extraction_meta.site == 'UM'], vmin=vmin, vmax=vmax,\n",
    "               col_cluster=False, robust=True, cmap=cmap, norm=norm)\n",
    "sns.clustermap(d[extraction_meta.site == 'UT'], vmin=vmin, vmax=vmax,\n",
    "               col_cluster=False, robust=True, cmap=cmap, norm=norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UM Strain\n",
    "with open('data/core.a.mags/Otu0001_vA.g.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([1, 24, 26, 27, 30, 37,   3, 31, 36])].index:\n",
    "        print(contig_id, file=handle)\n",
    "        \n",
    "with open('data/core.a.mags/Otu0001_vA.g.library.list', 'w') as handle:\n",
    "    extraction_ids = (list(cvrg_norm[extraction_meta.site == 'UM'].index)\n",
    "#                      + ['EXT-0237', 'EXT-0226', 'EXT-0107']\n",
    "                     )\n",
    "    for library_id in library[library.extraction_id.isin(extraction_ids)].index:\n",
    "        print(library_id, file=handle)\n",
    "        \n",
    "# UT Strain \n",
    "with open('data/core.a.mags/Otu0001_vB.g.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([1, 24, 26, 27, 30, 37,   2, 5, 25])].index:\n",
    "        print(contig_id, file=handle)\n",
    "        \n",
    "with open('data/core.a.mags/Otu0001_vB.g.library.list', 'w') as handle:\n",
    "    extraction_ids = ['EXT-0129', 'EXT-0071', 'EXT-0256',\n",
    "                      'EXT-0031', 'EXT-0255', 'EXT-0169',\n",
    "                      'EXT-0210', 'EXT-0165', 'EXT-0238',\n",
    "                      'EXT-0108', 'EXT-0204', 'EXT-0086']\n",
    "    for library_id in library[library.extraction_id.isin(extraction_ids)].index:\n",
    "        print(library_id, file=handle)\n",
    "        \n",
    "\n",
    "library.join(cvrg, on='extraction_id')[trusted_contigs].sum(1).to_csv('data/core.a.mags/Otu0001_vA.g.trusted_depth.tsv', sep='\\t', header=False)\n",
    "library.join(cvrg, on='extraction_id')[trusted_contigs].sum(1).to_csv('data/core.a.mags/Otu0001_vB.g.trusted_depth.tsv', sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Both have: 1 (core), 9 (core, missassembled?), 14 (16S)\n",
    "-   All individuals at UM have the (e.g. EXT-0296) OTU-1-UM genotype: 4 (genomic), 6 (plasmid)\n",
    "-   UT has some individuals with a genotype just like OTU-1-UM (e.g. EXT-0107)\n",
    "-   But also two additional genotypes...\n",
    "    -   Individuals with OTU-1-UT-A genotype (e.g. EXT-0255) have:\n",
    "        3 (genomic), 15 (genomic, missassembled?), 16 (genomic), 19 (plasmid)\n",
    "    -   Individuals with OTU-1-UT-B genotype (e.g. EXT-0071) have all four of the above\n",
    "        variable elements as _well_ as: 6 (plasmid)\n",
    "    -   [...]\n",
    "-   ACTUALLY: OTU-1-UT-B is not a genotype.  Instead, we're seeing individuals with both genotypes\n",
    "    -   there's a negative correlation between the\n",
    "        coverage of group 6 and group 19 (both plasmids) in these individuals.\n",
    "    -   One complication is the very-close-to-zero coverage of group 4 in some of these individuals.\n",
    "        This appears to be explained by the fact that it's already at lower coverage, since it's\n",
    "        probably genomic, so it's easy for us to miss it inindividuals with low abundance of that strain.\n",
    "-   I think that group 15 is composed of missassembled contigs that are chimeras of OTU-1-UM and OTU-1-UT\n",
    "    -   This is because we have high coverage in OTU-1-UT dominated samples and low (but not 0) coverage\n",
    "        in OTU-1-UM dominated samples.\n",
    "    -   This group should be included in reassemblies, but then the results need to be filtered by the\n",
    "        coverage in \"trusted samples\" of some sort.\n",
    "-   I think that group 6 contains SOME sequence (but not much) that is also found in OTU-1-UT\n",
    "-   The coverage of group 14 may be reduced in OTU-1-UT; why would this be?\n",
    "    Does it include a contig that's only found in OTU-1-UM, but is mostly composed\n",
    "    of rRNA operon sequence?\n",
    "-   I think one solution is to not split up this OTU, and then use coverage information to try and\n",
    "    recover it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cvrg.sort_values('contamination_score').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-four (Otu0007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0007_1', 'Otu0007_2']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 'core-k161_32879'  # Contig containing the 16S gene\n",
    "compare = 'core-k161_646850'  # Some other contig that we're confident is in this genome.\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(20,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage * np.log(group_cvrg.total_length)\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 5\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > contam_threshold].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   OTU-7 (formerly OTU-4, e.g. EXT-0204) : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/core.a.mags/Otu0007_vA.g.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([0])].index:\n",
    "        print(contig_id, file=handle)\n",
    "        \n",
    "with open('data/core.a.mags/Otu0007_vA.g.library.list', 'w') as handle:\n",
    "    for extraction in library[lambda x: x.extraction_id.isin(trusted_extractions)].index:\n",
    "        print(extraction, file=handle)\n",
    "        \n",
    "library.join(cvrg, on='extraction_id')[trusted_contigs].sum(1).to_csv('data/core.a.mags/Otu0007_vA.g.trusted_depth.tsv', sep='\\t', header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0009_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg.apply(lambda x: sp.stats.pearsonr(d_rabund[otus].sum(1), x)[0]).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_1902073', 'core-k161_37339',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(20,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage * np.log(group_cvrg.total_length)\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 30\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < 1].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > 1].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < 1].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   OTU-9 (e.g. EXT-0181) : 1, 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/core.a.mags/Otu0009_vA.g.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([1, 15])].index:\n",
    "        print(contig_id, file=handle)\n",
    "        \n",
    "with open('data/core.a.mags/Otu0009_vA.g.library.list', 'w') as handle:\n",
    "    for extraction in library[lambda x: x.extraction_id.isin(trusted_extractions)].index:\n",
    "        print(extraction, file=handle)\n",
    "        \n",
    "library.join(cvrg, on='extraction_id')[trusted_contigs].sum(1).to_csv('data/core.a.mags/Otu0009_vA.g.trusted_depth.tsv', sep='\\t', header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0005_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "bins = bins - set(['other'])\n",
    "\n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "                                  \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_395950', 'core-k161_572566',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 30)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(5,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage * np.log(group_cvrg.total_length)\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 30\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > contam_threshold].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   OTU-5 (e.g. EXT-0031) : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/core.a.mags/Otu0005_vA.g.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([0])].index:\n",
    "        print(contig_id, file=handle)\n",
    "        \n",
    "with open('data/core.a.mags/Otu0005_vA.g.library.list', 'w') as handle:\n",
    "    for extraction in library[lambda x: x.extraction_id.isin(trusted_extractions)].index:\n",
    "        print(extraction, file=handle)\n",
    "        \n",
    "library.join(cvrg, on='extraction_id')[trusted_contigs].sum(1).to_csv('data/core.a.mags/Otu0005_vA.g.trusted_depth.tsv', sep='\\t', header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-4 (Not OTU-four)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0004_1', 'Otu0004_2']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg.apply(lambda x: sp.stats.pearsonr(d_rabund[otus].sum(1), x)[0]).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_1006653', 'core-k161_795722',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(5,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage * np.log(group_cvrg.total_length)\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 30\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < 1].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > 1].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < 1].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   OTU-4 (e.g. EXT-0255) : 0, 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/core.a.mags/Otu0004_vA.g.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([0, 4])].index:\n",
    "        print(contig_id, file=handle)\n",
    "        \n",
    "with open('data/core.a.mags/Otu0004_vA.g.library.list', 'w') as handle:\n",
    "    for extraction in library[lambda x: x.extraction_id.isin(trusted_extractions)].index:\n",
    "        print(extraction, file=handle)\n",
    "        \n",
    "library.join(cvrg, on='extraction_id')[trusted_contigs].sum(1).to_csv('data/core.a.mags/Otu0004_vA.g.trusted_depth.tsv', sep='\\t', header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-49"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0049_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg.apply(lambda x: sp.stats.pearsonr(d_rabund[otus].sum(1), x)[0]).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_507188', 'core-k161_286685',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg*1e5, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(5,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage * np.log(group_cvrg.total_length)\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 10\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   OTU-49 (e.g. EXT-0071) : 1, 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/core.a.mags/Otu0049_vA.g.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([0, 1])].index:\n",
    "        print(contig_id, file=handle)\n",
    "        \n",
    "with open('data/core.a.mags/Otu0049_vA.g.library.list', 'w') as handle:\n",
    "    for extraction in library[lambda x: x.extraction_id.isin(trusted_extractions)].index:\n",
    "        print(extraction, file=handle)\n",
    "        \n",
    "library.join(cvrg, on='extraction_id')[trusted_contigs].sum(1).to_csv('data/core.a.mags/Otu0049_vA.g.trusted_depth.tsv', sep='\\t', header=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OTU-17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_thresh_factor = 1/3\n",
    "otus = ['Otu0017_1']\n",
    "bins = set()\n",
    "for otu in otus:\n",
    "    max_contrib = bin_otu_contrib[otu].max()\n",
    "    bins |= set(bin_otu_contrib[otu][lambda x: x > max_contrib * keep_thresh_factor].index)\n",
    "bins = bins - set(['other'])\n",
    "    \n",
    "print(bins)\n",
    "contig_ids = set(contig_bin[lambda x: x.bin_id.isin(bins)].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "contig_ids_sql = '\"' + '\", \"'.join(contig_ids) + '\"'\n",
    "\n",
    "cvrg = pd.read_sql(\"\"\"\n",
    "SELECT extraction_id, contig_id, SUM(coverage) AS coverage\n",
    "FROM contig_coverage\n",
    "JOIN library USING (library_id)\n",
    "WHERE contig_id IN ({})\n",
    "GROUP BY extraction_id, contig_id\n",
    "                   \"\"\".format(contig_ids_sql), con=con,\n",
    "                   index_col=['extraction_id', 'contig_id']).coverage.unstack('contig_id', fill_value=0)\n",
    "\n",
    "extraction_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM extraction\n",
    "JOIN sample USING (sample_id)\n",
    "JOIN mouse USING (mouse_id)\n",
    "JOIN (SELECT extraction_id, SUM(coverage) AS coverage\n",
    "      FROM library_total_coverage\n",
    "      JOIN library USING (library_id)\n",
    "      GROUP BY extraction_id) USING (extraction_id)\n",
    "                               \"\"\", con=con, index_col='extraction_id')\n",
    "\n",
    "contig_meta = pd.read_sql(\"\"\"\n",
    "SELECT *\n",
    "FROM contig_bin\n",
    "JOIN contig USING (contig_id)\n",
    "WHERE contig_id IN ({})\n",
    "                          \"\"\".format(contig_ids_sql),\n",
    "                         con=con, index_col='contig_id')\n",
    "\n",
    "cvrg = cvrg.loc[d_rabund.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed, compare = 'core-k161_2533146', 'core-k161_2411273',\n",
    "assert seed in contig_ids\n",
    "assert compare in contig_ids\n",
    "plt.scatter(seed, compare, data=cvrg, c=d_rabund[otus].sum(1).loc[cvrg.index], cmap='coolwarm')\n",
    "plt.plot([-1e3, 1e3], [-1e3, 1e3], c='k', lw=1, scalex=False, scaley=False)\n",
    "\n",
    "trusted_contigs = cvrg.apply(lambda x: sp.stats.pearsonr(cvrg[seed], x)[0])[lambda x: x > 0.99].index\n",
    "trusted_extractions = (cvrg[trusted_contigs].mean(1) / cvrg[trusted_contigs].std(1))[lambda x: x > 0.5].index\n",
    "\n",
    "print('{} trusted contigs and {} trusted extractions identified'.format(len(trusted_contigs), len(trusted_extractions)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cvrg_norm = cvrg.div(cvrg[trusted_contigs].mean(1), axis=0)\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='with_untrusted', alpha=0.8)\n",
    "cvrg_norm = cvrg_norm.loc[trusted_extractions]\n",
    "_ = plt.hist(np.log(cvrg_norm.mean()), bins=np.linspace(-4, 6), label='without_untrusted', alpha=0.8)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_data = np.sqrt(cvrg_norm)\n",
    "\n",
    "nn = range(1, 40)\n",
    "scores = []\n",
    "for n in nn:\n",
    "    score = BayesianGaussianMixture(n,\n",
    "                                  covariance_type='diag',\n",
    "    #                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "    #                              weight_concentration_prior=10,\n",
    "                                  random_state=1,\n",
    "                                 ).fit(cluster_data.T).score(cluster_data.T)\n",
    "    scores.append(score)\n",
    "plt.plot(nn, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgm = BayesianGaussianMixture(5,\n",
    "                              covariance_type='diag',\n",
    "#                              weight_concentration_prior_type='dirichlet_distribution',\n",
    "#                              weight_concentration_prior=10,\n",
    "                              random_state=1,\n",
    "                             ).fit(cluster_data.T)\n",
    "group_assign = pd.Series(bgm.predict(cluster_data.T), index=cvrg_norm.columns)\n",
    "group_cvrg = cvrg_norm.groupby(group_assign, axis='columns').mean().mean().to_frame(name='group_mean_mean_coverage')\n",
    "group_cvrg['group_mean_std_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').std().mean()\n",
    "group_cvrg['group_std_mean_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').mean().std()\n",
    "group_cvrg['group_max_coverage'] = cvrg_norm.groupby(group_assign, axis='columns').max().max()\n",
    "group_cvrg['total_length'] = contig_meta.groupby(group_assign).length.sum()\n",
    "group_cvrg['contamination_score'] = group_cvrg.group_std_mean_coverage / group_cvrg.group_mean_std_coverage * np.log(group_cvrg.total_length)\n",
    "group_cvrg.index.name = 'group'\n",
    "group_assign = group_assign.to_frame(name='group').join(group_cvrg, on='group')\n",
    "group_assign['bin_id'] = contig_meta.bin_id\n",
    "group_assign['length'] = contig_meta.length\n",
    "group_assign.sort_values(['contamination_score', 'length'], ascending=[True, False], inplace=True)\n",
    "# order = group_assign.index\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "\n",
    "for des, d in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "#    color = None\n",
    "    _ = ax.plot(d[group_assign.index].values.T, lw=1, alpha=0.25, color=color)\n",
    "#_ = ax.plot(group_assign.group_mean_coverage.values, color='k')\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "\n",
    "group_assign['contig_index'] = range(group_assign.shape[0])\n",
    "group_order = \\\n",
    "    (group_assign.groupby('group').contig_index\n",
    "                         .apply(lambda x: pd.Series({'middle': x.mean(),\n",
    "                                                     'left': x.min(),\n",
    "                                                     'right': x.max()}))).unstack().sort_values('left')\n",
    "contam_threshold = 10\n",
    "for inx, d in group_order.iterrows():\n",
    "    if group_cvrg.loc[inx].contamination_score > contam_threshold:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    elif group_cvrg.loc[inx].isna().contamination_score:\n",
    "        ax.axvline(d.left - 0.5, color='r', lw=0.5)\n",
    "        continue\n",
    "    else:\n",
    "        ax.axvline(d.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d.middle, cvrg_norm.max().max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg.loc[inx].total_length),\n",
    "                xy=(d.middle, cvrg_norm.max().max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "ax.set_yscale('symlog', linthreshy=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "group_cvrg.sort_values('contamination_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = (group_assign\n",
    "         [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score < contam_threshold].index)]\n",
    "         .groupby(['bin_id', 'group']).length.sum().unstack(fill_value=0))\n",
    "b = (group_assign\n",
    "                   [lambda x: x.group.isin(group_cvrg[lambda x: x.contamination_score > contam_threshold].index)]\n",
    "                   .groupby('bin_id').length.sum())\n",
    "b.name = 'contam'\n",
    "a.join(b, how='outer').fillna(0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cvrg_norm.groupby([extraction_meta.site, extraction_meta.treatment]).count().iloc[:,0])\n",
    "(cvrg_norm.groupby(group_assign.group, axis='columns').mean()\n",
    "          .groupby([extraction_meta.site, extraction_meta.treatment]).mean()).loc[:, group_cvrg[lambda x: x.contamination_score < contam_threshold].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(15, 5))\n",
    "\n",
    "ax.axhline(y=1, color='k', linestyle='--')\n",
    "artists = []\n",
    "plotting_order = []\n",
    "for des, d0 in cvrg_norm.groupby(extraction_meta.site):\n",
    "    color = color_map[des]\n",
    "    des_artists = ax.plot(d0[group_assign[lambda x: x.contamination_score < contam_threshold].index].values.T,\n",
    "                          lw=1, alpha=0.1, color=color)\n",
    "    artists.extend(des_artists)\n",
    "    plotting_order.extend(d0.index)\n",
    "#original_colors = {a: a.get_color() for a in artists}\n",
    "original_lw = {a: a.get_linewidth() for a in artists}\n",
    "original_alpha = {a: a.get_alpha() for a in artists}\n",
    "original_zorder = {a: a.get_zorder() for a in artists}\n",
    "otu_rabund = [d_rabund.loc[extraction_id][otus].sum() for extraction_id in plotting_order]\n",
    "\n",
    "group_cvrg_included = group_cvrg.loc[group_order.index][group_cvrg.contamination_score < contam_threshold]\n",
    "group_order_included = group_order.loc[group_cvrg_included.index]\n",
    "\n",
    "for inx, d1 in group_order_included.iterrows():\n",
    "    ax.axvline(d1.left - 0.5, color='k', lw=1, linestyle='--')\n",
    "    ax.annotate('({})'.format(inx), xy=(d1.middle, group_cvrg_included.group_max_coverage.max()), ha='center')\n",
    "    ax.annotate('{:0.02}'.format(group_cvrg_included.loc[inx].total_length),\n",
    "                xy=(d1.middle, group_cvrg_included.group_max_coverage.max() * 0.5),\n",
    "                ha='center', rotation=-90)\n",
    "\n",
    "annot = ax.annotate('', xy=(0.02, 0.8), xycoords=\"axes fraction\", rotation=90)\n",
    "ax.set_yscale('symlog', linthreshy=1)\n",
    "fig.tight_layout()\n",
    "\n",
    "def _init():\n",
    "    return artists\n",
    "\n",
    "def _animate(i):\n",
    "    j = i - 1\n",
    "    artists[i].set_linewidth(1)\n",
    "    artists[i].set_alpha(0.9)\n",
    "    artists[i].set_zorder(999)\n",
    "    artists[j].set_linewidth(original_lw[artists[j]])\n",
    "    artists[j].set_alpha(original_alpha[artists[j]])\n",
    "    artists[j].set_zorder(original_zorder[artists[j]])\n",
    "    annot.set_text('{} ({:0.1f}%)'.format(plotting_order[i], otu_rabund[i]*100))\n",
    "    return [artists[i], artists[j], annot]\n",
    "\n",
    "anim = animation.FuncAnimation(fig, _animate, init_func=_init,\n",
    "                               frames=cvrg_norm.shape[0], interval=200, blit=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HTML(anim.to_html5_video())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   OTU-17 (e.g. EXT-0243) : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/core.a.mags/Otu0017_vA.g.contigs.list', 'w') as handle:\n",
    "    for contig_id in group_assign[lambda x: x.group.isin([2])].index:\n",
    "        print(contig_id, file=handle)\n",
    "        \n",
    "with open('data/core.a.mags/Otu0017_vA.g.library.list', 'w') as handle:\n",
    "    for extraction in library[lambda x: x.extraction_id.isin(trusted_extractions)].index:\n",
    "        print(extraction, file=handle)\n",
    "        \n",
    "library.join(cvrg, on='extraction_id')[trusted_contigs].sum(1).to_csv('data/core.a.mags/Otu0017_vA.g.trusted_depth.tsv', sep='\\t', header=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "102px",
    "width": "189px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "193px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}